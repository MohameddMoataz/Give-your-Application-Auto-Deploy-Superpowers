version: 2.1
commands:
  install-dependencies:
    steps:
      - run:
          name: Installing packages
          command: |
            sudo apt update
            sudo apt install -y tar gzip curl software-properties-common
      - run:
          name: Installing aws-cli
          command: |
            curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
            unzip awscliv2.zip
            sudo ./aws/install
      - run:
          name: Installing ansible
          command: |
            sudo add-apt-repository --yes --update ppa:ansible/ansible
            sudo apt install ansible

  destroy-environment:
    description: Destroy backend and frontend cloudformation stacks given a workflow ID.
    parameters:
      workflow_id:
        type: string      
    steps:
      - run:
          name: Destroy environments
          when: on_fail
          command: |
            echo "Destroying environment: << parameters.workflow_id >> "

  revert-migrations:
    description: Revert the last migration if successfully run in the current workflow.
    parameters:
      workflow_id:
        type: string      
    steps:
      - run:
          name: Revert migrations
          when: on_fail
          command: |
              # Your Memstash or kvdb.io GET URL code goes here
              # Example: Memstash.io
              SUCCESS=$(curl -H "token: e52b52de-ee26-41a5-86e8-e8dcc3d995a5" --request GET https://api.memstash.io/values/migration_<< parameters.workflow_id >>)
              # Example: kvdb.io
              SUCCESS=$(curl --insecure  https://kvdb.io/9GE4jRtKznmVKRfvdBABBe/migration_<< parameters.workflow_id >>)
              # Logic for reverting the database state
              if (( $SUCCESS == 1 ));
              then
                  cd ~/project/backend
                  npm install
                  npm run migration:revert
              fi  
            
jobs:
  build-frontend:
    docker:
      - image: circleci/node:13.8.0
    steps:
      - checkout
      - restore_cache:
          keys: [frontend-build]
      - run:
          name: Build front-end
          command: |
            cd frontend
            npm install
            npm run build
      - save_cache:
          paths: [frontend/node_modules]
          key: frontend-build

  build-backend:
    docker:
      - image: circleci/node:13.8.0
    steps:
      - checkout
      - restore_cache:
          keys: [backend-build]
      - run:
          name: Back-end build
          command: |
             cd backend
             npm install
             npm run build
      - save_cache:
          paths: [backend/node_modules]
          key: backend-build

  test-frontend:
    docker: 
      - image: circleci/node:13.8.0
      # Docker image here
    steps:
      - checkout
      - restore_cache:
          keys: [frontend-test]
      - run:
          name: front-end test
          command: |
             cd frontend
             npm install
             npm run test

  test-backend:
    docker: 
      - image: circleci/node:13.8.0
      # Docker image here
    steps:
      - checkout
      - restore_cache:
          keys: [backend-test]
      - run:
          name: back-end test
          command: |
             cd backend
             npm install
             npm run test
            
  scan-frontend:
    docker: 
      - image: circleci/node:13.8.0
      # Docker image here
    steps:
      - checkout
      - restore_cache:
          keys: [frontend-scan]
      - run:
          name: front-end sacn
          command: |
            cd frontend
            npm install
            npm audit fix --audit-level=critical

  scan-backend:
    docker: 
      - image: circleci/node:13.8.0
      # Docker image here
    steps:
      - checkout
      - restore_cache:
          keys: [backend-scan]
      - run:
          name: back-end sacn
          command: |
            cd backend
            npm install
            npm audit fix --audit-level=critical

  deploy-infrastructure:
    docker:
      - image: cimg/base:2021.04 #amazon/aws-cli doesn't have tar
      # Docker image here that supports AWS CLI
    steps:
      - checkout
      - install-dependencies 
      - run:
          name: Ensure back-end infrastructure exists
          command: |
            aws cloudformation deploy \
              --template-file .circleci/files/backend.yml \
              --stack-name "udapeople-backend-${CIRCLE_WORKFLOW_ID:0:7}"\
              --parameter-overrides ID="${CIRCLE_WORKFLOW_ID:0:7}"\
              --tags project=udapeople
      - run:
          name: Ensure front-end infrastructure exist
          command: |
            aws cloudformation deploy \
              --template-file .circleci/files/frontend.yml \
              --stack-name "udapeople-frontend-${CIRCLE_WORKFLOW_ID:0:7}"\
              --parameter-overrides ID="${CIRCLE_WORKFLOW_ID:0:7}" \
              --tags project=udapeople
      - run:
          name: Add back-end ip to ansible inventory
          command: |
            aws ec2 describe-instances \
              --query 'Reservations[*].Instances[*].PublicIpAddress' \
              --filters "Name=tag:project,Values=udapeople" \
              --output text >> .circleci/ansible/inventory.txt
              cat .circleci/ansible/inventory.txt
      - persist_to_workspace:
          root: ~/
          paths:
            - project/.circleci/ansible/inventory.txt
      - destroy-environment:
          workflow_id: '${CIRCLE_WORKFLOW_ID:0:7}'
      # Here's where you will add some code to rollback on failure      

  configure-infrastructure:
    docker:
      - image: python:3.7-alpine3.11
      # Docker image here that supports Ansible
    steps:
      # Checkout code from git
      - checkout
            # attach workspace
      - attach_workspace:
          at: ~/
      - run:
          name: Install dependencies
          command: |
            apk add --update ansible # install the dependencies needed for your playbook
            cat .circleci/ansible/inventory.txt
      - run:
          name: Configure server
          command: |
            echo ENVIRONMENT=production > "backend/.env"
            echo TYPEORM_CONNECTION=postgres >> "backend/.env"
            echo TYPEORM_ENTITIES=./src/modules/domain/**/*.entity.ts >> "backend/.env"
            echo TYPEORM_MIGRATIONS=./src/migrations/*.ts >> "backend/.env"
            echo TYPEORM_MIGRATIONS_DIR=./src/migrations >> "backend/.env"
            echo NODE_ENV=production >> "backend/.env"
            echo TYPEORM_HOST=$TYPEORM_HOST >> "backend/.env"
            echo TYPEORM_PORT=$TYPEORM_PORT >> "backend/.env"
            echo TYPEORM_USERNAME=$TYPEORM_USERNAME >> "backend/.env"
            echo TYPEORM_PASSWORD=$TYPEORM_PASSWORD >> "backend/.env"
            echo TYPEORM_DATABASE=$TYPEORM_DATABASE >> "backend/.env"
            ansible-playbook \
              -i .circleci/ansible/inventory.txt \
              .circleci/ansible/configure-server.yml

  run-migrations:
    docker:
      # Docker image here that supports NodeJS
      - image: circleci/node:13.8.0
    steps:
      # Checkout code from git
      - checkout
      - run:
          name: Run migrations
          command: |
            cd backend
            npm install
            npm run migrations > migrations_dump.txt
      - run:
          name: Send migration status to memstash.io
          command: |   
            if grep -q "has been executed successfully." ~/project/backend/migrations_dump.txt
            then
              # If you are using memstash.io, generate the token "7933fe63-4687-4fa1-8426-aa25aa1730ec" on the website
              curl -H "Content-Type: text/plain" -H "token: 7933fe63-4687-4fa1-8426-aa25aa1730ec" --request PUT --data "1" https://api.memstash.io/values/migration_${CIRCLE_WORKFLOW_ID:0:7}
              # If you are using kvdb.io, generate the bucket ID "9GE4jRtKznmVKRfvdBABBe" in your local terminal first
              curl https://kvdb.io/9GE4jRtKznmVKRfvdBABBe/migration_${CIRCLE_WORKFLOW_ID:0:7}  -d '1'
            fi
     # Here's where you will add some code to rollback on failure
      - destroy-environment:
          workflow_id: '${CIRCLE_WORKFLOW_ID:0:7}'
      - revert-migrations:
          workflow_id: '${CIRCLE_WORKFLOW_ID:0:7}'

  deploy-frontend:
    docker:
      - image: circleci/node:13.8.0
    steps:
      - checkout
      - attach_workspace:
          at: ~/
      - run:
          name: Install dependencies
          command: |
            cd frontend
            sudo npm install webpack-dev-server -g
            sudo npm install
      - run:
          name: Get backend url
          command: |
            export BACKEND_IP=$(sed -n 2p .circleci/ansible/inventory.txt)
            export API_URL="http://${BACKEND_IP}:3030"
            echo ENVIRONMENT=production > "frontend/.env"
            echo NODE_ENV=production >> "frontend/.env"
            echo API_URL=$API_URL >> "frontend/.env"
            echo $API_URL
      - run:
          name: Build frontend
          command: |
            cd frontend
            ls -la
            cat .env
            npm run build
      - run:
          name: Deploy frontend objects
          command: |
            aws s3 cp --recursive frontend/dist "s3://udapeople-${CIRCLE_WORKFLOW_ID:0:7}"
    
  deploy-backend:
    docker:
      - image: python:3.7-alpine3.11
    steps:
      - checkout
      - add_ssh_keys:
          fingerprints: ["5f:7b:d4:d7:d8:88:61:0b:21:eb:b9:cc:cd:ed:53:c1"]
      - attach_workspace:
          at: ~/
      - run:
          name: Install dependencies
          command: |
            apk add --update ansible openssh-client tar gzip
      - restore_cache:
          keys: ["backend-dist"]  # -<< pipeline.id >>
      - run:
          name: Deploy backend
          command: |
            cd /home
            tar czf backend.tar.gz -P /home/circleci/project/backend/dist
      - run:
          name: Deploy backend 2
          command: |
            export ANSIBLE_HOST_KEY_CHECKING=False
            ansible-playbook \
              -i .circleci/ansible/inventory.txt \
              .circleci/ansible/deploy-backend.yml
      - run:
          name: Install AWS CLI for rollback
          when: on_fail
          command: |
            apk add --update py3-pip && pip3 install --upgrade pip && pip3 install awscli

  smoke-test:
    docker:
      - image: python:3.7-alpine3.11
    steps:
      - checkout
      - run:
          name: Install dependencies
          command: |
            apk add --no-cache curl
            apk add --no-cache --upgrade bash
            apk add --no-cache --update ansible
            apk add --no-cache openssh-client
            pip3 install awscli
      - run:
          name: backend smoke test
          command: |
            PUBLIC_DNS=$(curl -H "token: ${CIRCLE_WORKFLOW_ID}" --request GET https://api.memstash.io/values/public_dns)
            echo ${PUBLIC_DNS}
            if curl -s "http://${PUBLIC_DNS}:3030/api/status" | grep "ok"
            then
              return 0
            else
              return 1
            fi
      - run:
          name: frontend smoke test
          command: |
            URL="http://udapeople-s3bucket-${CIRCLE_WORKFLOW_ID}.s3-website.us-east-2.amazonaws.com/#/employees"
            if curl -s ${URL} | grep "Welcome"
            then
              return 0
            else
              return 1
            fi
     
      # Here's where you will add some code to rollback on failure  

  cloudfront-update:
    docker:
      - image: cimg/base:2021.04
    steps:
      - checkout
      - install-dependencies 
      - run:
          name: Updating cloudfront distribution
          command: |
            aws cloudformation deploy \
              --stack-name InitialStack \
              --template-file ./infra/cloudformation/cloudfront.yml \
              --parameter-overrides WorkflowId="${CIRCLE_WORKFLOW_ID:0:7}" \
              --tags project=udapeople
# Here's where you will add some code to rollback on failure  

  cleanup:
    docker:
      - image: cimg/base:2021.04
    steps:
      - checkout            
      - install-dependencies 
      - run:
          name: Removing old stacks and files
          command: |
            BUCKETS=$(curl "https://api.thisdb.com/v1/${THISDB_BUCKET}" \
              -H "X-Api-Key: ${THISDB_API_KEY}")
            if [[ $BUCKETS =~ latest-stack ]]; then
              LATEST_STACK_ID=$(curl "https://api.thisdb.com/v1/${THISDB_BUCKET}/latest-stack" -H "X-Api-Key: ${THISDB_API_KEY}")
              CURRENT_STACK_ID="${CIRCLE_WORKFLOW_ID:0:7}"
              echo "LATEST_STACK_ID: $LATEST_STACK_ID"
              echo "CURRENT_STACK_ID: $CURRENT_STACK_ID"
              aws cloudformation delete-stack --stack-name "udapeople-frontend-${LATEST_STACK_ID}"
              aws cloudformation delete-stack --stack-name "udapeople-backend-${LATEST_STACK_ID}"
              aws s3 rm "s3://udapeople-${LATEST_STACK_ID}" --recursive
            else
              echo "Skipping..."
            fi
      - run:
          name: Storing current stack workflow id
          command: |
            curl "https://api.thisdb.com/v1/${THISDB_BUCKET}/latest-stack" \
              -H "X-Api-Key: ${THISDB_API_KEY}" \
              -d "${CIRCLE_WORKFLOW_ID:0:7}"            

workflows:
  default:
    jobs:
      - build-frontend
      - build-backend
      - test-frontend:
          requires: [build-frontend]
      - test-backend:
          requires: [build-backend]
      - scan-backend:
          requires: [build-backend]
      - scan-frontend:
          requires: [build-frontend]
      - deploy-infrastructure:
          requires: [test-frontend, test-backend, scan-frontend, scan-backend]
      - configure-infrastructure:
          requires: [deploy-infrastructure]
      - run-migrations:
          requires: [configure-infrastructure]
      - deploy-frontend:
          requires: [run-migrations]
      - deploy-backend:
          requires: [run-migrations]
      - smoke-test:
          requires: [deploy-backend, deploy-frontend]
      - cloudfront-update:
          requires: [smoke-test]
      - cleanup:
          requires: [cloudfront-update]